{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "MIT License\n",
    "Copyright (c) 2016 Francesco Gadaleta \n",
    "\n",
    "Permission is hereby granted, free of charge, to any person obtaining a copy \n",
    "of this software and associated documentation files (the \"Software\"), to deal \n",
    "in the Software without restriction, including without limitation the rights \n",
    "to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies \n",
    "of the Software, and to permit persons to whom the Software is furnished to do \n",
    "so, subject to the following conditions:\n",
    "\n",
    "The above copyright notice and this permission notice shall be included in all \n",
    "copies or substantial portions of the Software.\n",
    "\n",
    "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR \n",
    "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, \n",
    "FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE \n",
    "AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, \n",
    "WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN \n",
    "CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n",
    "\n",
    "--------------------------------------------------------------------------------------\n",
    "Note: \n",
    "Please build training/testing set before running this script.\n",
    "Make sure to create the local path that have been hardcoded in the following scripts, \n",
    "then execute\n",
    "\n",
    "    % python make_data_class_0.py\n",
    "    % python make_data_class_1.py\n",
    "--------------------------------------------------------------------------------------- \n",
    "\n",
    "\"\"\" \n",
    "\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "\n",
    "import matplotlib\n",
    "# Force matplotlib to not use any Xwindows backend.\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.style as ms\n",
    "ms.use('seaborn-muted')\n",
    "%matplotlib inline\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "from keras.models import model_from_json\n",
    "\n",
    "import skimage.io as io \n",
    "\n",
    "import os \n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import utils as ut\n",
    "\n",
    "import librosa\n",
    "import librosa.display\n",
    "import IPython.display\n",
    "import numpy as np\n",
    "from skimage.measure import block_reduce\n",
    "import skimage.io as io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# network configuration\n",
    "batch_size = 32\n",
    "# number of epochs\n",
    "nb_epoch = 5\n",
    "# number of convolutional filters to use\n",
    "nb_filters = 32\n",
    "# number of classes \n",
    "nb_classes = 2\n",
    "# size of pooling area for max pooling\n",
    "pool_size = (2, 2)\n",
    "# convolution kernel size\n",
    "kernel_size = (3, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# the data, shuffled and split between train and test sets\n",
    "# we save generated images here (make sure there is space)\n",
    "path_class_0 = './archive/ahem_data/class_0/'\n",
    "path_class_1 = './archive/ahem_data/class_1/'\n",
    "\n",
    "# load filenames into lists \n",
    "class0_files = [f for f in listdir(path_class_0) if isfile(join(path_class_0, f))]\n",
    "class1_files = [f for f in listdir(path_class_1) if isfile(join(path_class_1, f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prepare training set\n",
    "X_t = []\n",
    "Y_t = []\n",
    "\n",
    "for fn in class0_files[:100]:\n",
    "    img = io.imread(os.path.join(path_class_0, fn))\n",
    "    img = img.transpose((2,0,1))\n",
    "    img = img[:3, :, :]\n",
    "    X_t.append(img)\n",
    "    Y_t.append(0)\n",
    "\n",
    "for fn in class1_files[:100]:\n",
    "    img = io.imread(os.path.join(path_class_1, fn))\n",
    "    img = img.transpose((2,0,1))\n",
    "    img = img[:3, :, :]\n",
    "    X_t.append(img)\n",
    "    Y_t.append(1)\n",
    "\n",
    "X_t = np.asarray(X_t)\n",
    "X_t = X_t.astype('float32')\n",
    "X_t /= 255\n",
    "\n",
    "Y_t = np.asarray(Y_t)\n",
    "Y_t = np_utils.to_categorical(Y_t, nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_rows, img_cols = X_t.shape[2], X_t.shape[3] \n",
    "# input image dimensions\n",
    "img_channels = 3               # RGB\n",
    "input_shape = (3, img_rows, img_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## test set\n",
    "X_test = []\n",
    "Y_test = [] \n",
    "\n",
    "for fn in class0_files[6000:8000]:\n",
    "    img = io.imread(os.path.join(path_class_0, fn))\n",
    "    img = img.transpose((2,0,1))\n",
    "    img = img[:3, :, :]\n",
    "    X_test.append(img)\n",
    "    Y_test.append(0)\n",
    "\n",
    "for fn in class1_files[6000:8000]:\n",
    "    img = io.imread(os.path.join(path_class_1, fn))\n",
    "    img = img.transpose((2,0,1))\n",
    "    img = img[:3, :, :]\n",
    "    X_test.append(img)\n",
    "    Y_test.append(1)\n",
    "\n",
    "X_test = np.asarray(X_test)\n",
    "Y_test = np.asarray(Y_test)\n",
    "X_test = X_test.astype('float32')\n",
    "X_test /= 255\n",
    "\n",
    "Y_test = np_utils.to_categorical(Y_test, nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_model():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Convolution2D(nb_filters, kernel_size[0], kernel_size[1],\n",
    "                            border_mode='valid',\n",
    "                            input_shape=input_shape))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Convolution2D(nb_filters, kernel_size[0], kernel_size[1]))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=pool_size))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    \n",
    "    model.add(Convolution2D(nb_filters, 3, 3, border_mode='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Convolution2D(nb_filters, 3, 3))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(nb_classes))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adadelta',\n",
    "                  metrics=['accuracy'])\n",
    "    return model \n",
    "\n",
    "def load_image(filename):\n",
    "    img = io.imread(filename)\n",
    "    img = img.transpose((2,0,1))\n",
    "    img = img[:3, :, :]\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = make_model()\n",
    "model.compile(loss='binary_crossentropy', optimizer='adadelta', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for e in xrange(3):\n",
    "    model.fit(X_t, Y_t, \n",
    "              #validation_data=(X_test, Y_test), \n",
    "              batch_size=batch_size, \n",
    "              nb_epoch=1, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying if all this stuff works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions = model.predict_classes(X_test)\n",
    "\n",
    "y = []\n",
    "for e in Y_test:\n",
    "    if e[0]> e[1]:\n",
    "        y.append(0)\n",
    "    else:\n",
    "        y.append(1)\n",
    "\n",
    "print('how many did we guess out of ', Y_test.shape)\n",
    "np.sum(y == predictions)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions on new audio sample "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# the data, shuffled and split between train and test sets\n",
    "path_newsample = '/archive/ahem_data/new_sample/'\n",
    "newsample_files = [f for f in listdir(path_newsample) if isfile(join(path_newsample, f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prepare test set as we did for training set\n",
    "X_test = []\n",
    "\n",
    "for fn in newsample_files:\n",
    "    img = io.imread(os.path.join(path_newsample, fn))\n",
    "    img = img.transpose((2,0,1))\n",
    "    img = img[:3, :, :]\n",
    "    X_test.append(img)\n",
    "\n",
    "X_test = np.asarray(X_test)\n",
    "X_test = X_test.astype('float32')\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# grab a large cup of coffee this will take a while  \n",
    "predictions = model.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# collect all indices of noisy samples (class 1)\n",
    "# start position is encoded in filename (a trick to run this in parallel with no sequential order)\n",
    "noisy_frames = np.where(predictions==1)[0]\n",
    "noisy_files = [newsample_files[n] for n in noisy_frames]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Playback and clean new samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load a sound with a lot of \"ahem\" in it\n",
    "path = '/archive/ahem_data'\n",
    "sound_file_paths = [os.path.join(path, \"provocation_dirty.wav\")]\n",
    "sound_names = [\"dirty\"]\n",
    "raw_sounds = ut.load_sound_files(sound_file_paths)\n",
    "windowsize = 6000 \n",
    "# create positive samples\n",
    "audiosamples = raw_sounds[0]\n",
    "numsamples = audiosamples.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "original_audio = audiosamples\n",
    "clean_audio = audiosamples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Playback from ipython (cool uh?)\n",
    "IPython.display.Audio(data=original_audio, rate=44100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "noisy_start = []\n",
    "for fn in noisy_files:\n",
    "    noisy_start.append(int(fn.split('_')[2].split('.')[0]))\n",
    "\n",
    "noisy_start.sort(reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clean_audio = audiosamples\n",
    "prev_idx = 0\n",
    "for start in xrange(1, len(noisy_start)):\n",
    "    prev_pos  = noisy_start[prev_idx]\n",
    "    current_pos = noisy_start[start]\n",
    "    diff = prev_pos - current_pos\n",
    "    prev_idx += 1\n",
    "\n",
    "    # set volume to zero for 'ahem' samples\n",
    "    clean_audio[current_pos:current_pos+windowsize] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Play it back!\n",
    "IPython.display.Audio(data=clean_audio, rate=44100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# save to file and enjoy the clean episode!\n",
    "librosa.output.write_wav('/archive/ahem_data/cleaned.wav', clean_audio, sr=44100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audio analytics without deep learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ut.plot_waves(sound_names,raw_sounds)\n",
    "ut.plot_specgram(list(sound_names[3:]), list(raw_sounds[3:]))\n",
    "ut.plot_log_power_specgram(sound_names,raw_sounds)\n",
    "\n",
    "# traditional audio features \n",
    "mfccs, chroma, mel, contrast,tonnetz = ut.extract_feature('./data/jingle.wav')\n",
    "ut.specgram_frombuffer(raw_sounds[0][0:44100], 6, 6, fname='/archive/buffer.png', show=True)\n",
    "\n",
    "# found a good model to analyze the audio features above \n",
    "# and... good luck!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
